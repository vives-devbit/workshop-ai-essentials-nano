{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZBFzjClURz"
      },
      "source": [
        "# Trainen van een simpel TensorFlow Lite model voor microcontrollers\n",
        "\n",
        "Deze notebook demonstreert het proces voor het trainen van een `2.5 kB` model met TensorFlow en het converteren voor gebruik met TensorFlow Lite voor microcontrollers.\n",
        "\n",
        "Deep learning netwerken leren patronen in onderliggende data te modelleren. Hier gaan we een netwerk trainen om gegevens te modelleren die zijn gegenereerd door een sinus functie. Dit zal resulteren in een model dat een waarde, `x`, kan aannemen en zijn sinus, `y`, kan voorspellen.\n",
        "\n",
        "Deze notebook is gebaseerd op de originele [hello world demo van TensorFlow Lite](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In een virtuele environment\n",
        "\n",
        "Je kan deze notebook ook runnen op een computer in een virtuele python environment aan de hand van `conda`.\n",
        "\n",
        "```bash\n",
        "conda create -n ts-flow python=3.9\n",
        "conda activate ts-flow\n",
        "```\n",
        "\n",
        "Vergeet in VSCode dan niet om je kernel correct te zetten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UQblnrLd_ET"
      },
      "source": [
        "## Configure Defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PYwRFppd-WB"
      },
      "outputs": [],
      "source": [
        "# Define paths to model files\n",
        "import os\n",
        "MODELS_DIR = 'models/'\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + 'model'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dh4AXGuHWeu1"
      },
      "source": [
        "## Opzetten van omgeving\n",
        "\n",
        "Installeren van de nodige libraries. Hier in commentaar gezet omdat dit reeds voor jullie is gedaan. Dit duurt ook vrij lang.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr1VLfotanf6",
        "outputId": "510567d6-300e-40e2-f5b8-c3520a3f3a8b"
      },
      "outputs": [],
      "source": [
        "# ! pip install tensorflow==2.4.0\n",
        "# ! pip install pandas\n",
        "# ! pip install matplotlib"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tx9lOPWh9grN"
      },
      "source": [
        "Importeren van de nodige libraries.\n",
        "- **tensorflow:** open source machine learning library\n",
        "- **keras:** high-level API rond tensorflow voor deep learning\n",
        "- **numpy:** wiskundige library\n",
        "- **panda:** data manipulatie library\n",
        "- **matplotlib:** library voor grafieken\n",
        "- **math:** wiskundige library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53PBJBv1jEtJ"
      },
      "outputs": [],
      "source": [
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "\n",
        "# Keras is TensorFlow's high-level API for deep learning\n",
        "from tensorflow import keras\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "# Pandas is a data manipulation library \n",
        "import pandas as pd\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# Math is Python's math library\n",
        "import math\n",
        "\n",
        "# Set seed for experiment reproducibility\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p-PuBEb6CMeo"
      },
      "source": [
        "## Maken van een simpele dataset\n",
        "\n",
        "In deze stap gaan we een artificiële dataset generen. In de realiteit zouden we dit bv. kunnen opmeten met een automatische meetopstelling.\n",
        "\n",
        "In de praktijk is het model maar zo goed als de originele dataset waarmee we het trainen. Vandaar dat het in de praktijk heel belangrijk is om een goede dataset te hebben."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7gB0-dlNmLT-"
      },
      "source": [
        "### 1. Genereren van de data\n",
        "\n",
        "In onderstaande code genereren we een random set van `x` waarden. Voor elke `x` waarde berekenen we dan de `sinus(x)`, welke dan onze `y` waarden worden.\n",
        "\n",
        "Het resultaat geven we terug in een grafiek."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uKjg7QeMDsDx",
        "outputId": "2ded7790-62a2-40df-a4f9-429f2dd5357f"
      },
      "outputs": [],
      "source": [
        "# Number of sample datapoints\n",
        "SAMPLES = 1000\n",
        "\n",
        "# Generate a uniformly distributed set of random numbers in the range from\n",
        "# 0 to 2π, which covers a complete sine wave oscillation\n",
        "x_values = np.random.uniform(\n",
        "    low=0, high=2*math.pi, size=SAMPLES).astype(np.float32)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "# Calculate the corresponding sine values\n",
        "y_values = np.sin(x_values).astype(np.float32)\n",
        "\n",
        "# Plot our data. The 'b.' argument tells the library to print blue dots.\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iWOlC7W_FYvA"
      },
      "source": [
        "### 2. Toevoegen van ruis\n",
        "\n",
        "Onze data werd rechtstreeks gegeneerd door de sinus functie en heeft daarom een mooie vorm.\n",
        "\n",
        "Machine learning modellen zijn echter goed in het extraheren van de onderliggende betekenis van rommelige data uit de echte wereld. Om dit aan te tonen, kunnen we wat ruis aan onze data toevoegen om een iets realistischere situatie te benaderen.\n",
        "\n",
        "Onderstaande code voegt wat willekeurige ruis toe aan elke waarde. Het resultaat wordt opnieuw in een grafiek weergegeven."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "i0FJe3Y-Gkac",
        "outputId": "10d4d994-3b78-4512-a029-5ef0e444d75c"
      },
      "outputs": [],
      "source": [
        "# Add a small random number to each y value\n",
        "y_values += 0.1 * np.random.randn(*y_values.shape)\n",
        "\n",
        "# Plot our data\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Up8Xk_pMH4Rt"
      },
      "source": [
        "### 3. Splits de data\n",
        "\n",
        "De dataset die we nu hebben gemaakt is een benadering van een realistische dataset. Deze waarden gaan we nu gebruiken om ons model te trainen.\n",
        "\n",
        "Om de nauwkeurigheid van het model dat we trainen te evalueren, moeten we de voorspellingen vergelijken met echte gegevens en controleren hoe goed ze overeenkomen. Deze evaluatie vindt plaats tijdens de training (waar dit **validatie** wordt genoemd) en na de training (ook wel **testen** genoemd). In beide gevallen is het belangrijk dat we nieuwe gegevens gebruiken die nog niet zijn gebruikt om het model te trainen.\n",
        "\n",
        "We dienen onze dataset dus op te splitsen in 3 groepen:\n",
        "\n",
        "1. **Trainingsdata:** 60% (het grootste aantal gebruiken we om het model te trainen)\n",
        "2. **Validatie:** 20% (wordt gebruikt tijdens het trainen om model bij te sturen)\n",
        "3. **Testen:** 20% (wordt gebruikt na het trainen om te kijken hoe goed het model werkt)\n",
        "\n",
        "Onderstaande code zal onze originele dataset opsplitsen in deze verschillende sets en grafisch weergeven met elk hun eigen kleur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nNYko5L1keqZ",
        "outputId": "e1e6915d-5cfe-4086-d20f-8e3aebd80292"
      },
      "outputs": [],
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Training\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Testing\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfdelu1TmgPk"
      },
      "source": [
        "## Training\n",
        "\n",
        "Nu onze dataset klaar is, kunnen we starten met het maken van een neuraal netwerk om het vervolgens te trainen met de data die we uit vorige stap hebben."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t5McVnHmNiDw"
      },
      "source": [
        "### 1. Creëren van een Model\n",
        "\n",
        "In deze stap gaan we een simpel neural netwerk model bouwen dat een input waarde (hier in ons geval de `x` parameter) neemt en dit gebruikt om de bijhorende sinus waarde te voorspellen (hier voorgesteld door `y`).\n",
        "\n",
        "In dit geval hebben we te maken met **regressie**. Regressie is een statistische methode die in AI wordt gebruikt om de relatie tussen een afhankelijke variabele en een of meer onafhankelijke variabelen te modelleren. Het wordt gebruikt voor het voorspellen van continue waarden (reële getallen) voor een bepaalde invoer. Het model wordt vervolgens gebruikt om voorspellingen te doen op nieuwe, ongeziene gegevens.\n",
        "\n",
        "TODO: Is onderstaande correct?\n",
        "\n",
        "Het neuraal netwerk zal bestaan uit volgende onderdelen:\n",
        "\n",
        "1. Een input die onze `x` waarde zal bevatten\n",
        "2. Een **hidden layer** met 8 **neuronen**\n",
        "    - Op basis van deze input zal elk neuron _geactiveerd_ worden met een bepaalde waarde en dit op basis van zijn interne parameters (_gewicht_ (_weight_) en _offset_ (_bias_)). De activeringsgraad van een neuron wordt uitgedrukt als een getal.\n",
        "3. Een **output** layer die het resultaat van de 8 neuronen zal samennemen om een voorspelling te maken van de `y` waarde\n",
        "    - De activeringsnummers van onze verborgen layer zullen als invoer worden gebruikt voor onze output layer, die een enkele neuron is. Het zal zijn eigen gewichten en offset toepassen op deze invoer en zijn eigen activering berekenen, die zal resulteren in een `y`-waarde.\n",
        "\n",
        "<!-- De input is hier niet echt een layer maar eerder een input object. Meer info hier: [https://www.tensorflow.org/guide/keras/sequential_model](https://www.tensorflow.org/guide/keras/sequential_model). -->\n",
        "\n",
        "![Neural Network](./img/neural_network.jpg)\n",
        "\n",
        "TODO: Update drawing above\n",
        "\n",
        "De code hieronder maakt een model zoals we hierboven hebben beschreven. Eens dit samengesteld is compileren we dit zodat het klaar is om te trainen.\n",
        "\n",
        "Als output zie je een klein overzicht van je gemaakt model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD60bE8cXQId"
      },
      "outputs": [],
      "source": [
        "# We'll use Keras to create a simple model architecture\n",
        "model_1 = tf.keras.Sequential(name=\"basic-model\")\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 8 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model_1.add(keras.layers.Dense(8, activation='relu', input_shape=(1,), name=\"hidden-layer\"))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model_1.add(keras.layers.Dense(1, name=\"output-layer\"))\n",
        "\n",
        "# Compile the model using the standard 'adam' optimizer and the mean squared error or 'mse' loss function for regression.\n",
        "model_1.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Output some information about the model\n",
        "model_1.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O0idLyRLQeGj"
      },
      "source": [
        "### 2. Trainen van het Model\n",
        "\n",
        "Zodra we het model hebben gedefinieerd, kunnen we onze gegevens gebruiken om het te **trainen**. Training bestaat uit aanvoeren van een `x`-waarde aan het neurale netwerk, controleren hoe ver de output van het netwerk afwijkt van de verwachte `y`-waarde en het aanpassen van de gewichten en offsets van de neuronen, zodat de kans groter is dat de output de volgende keer correct is.\n",
        "\n",
        "Training voert dit proces meerdere keren uit op de volledige dataset en elke volledige doorloop wordt een **epoch** genoemd. Het aantal epochs dat tijdens de training moet worden uitgevoerd, is een parameter die we kunnen instellen.\n",
        "\n",
        "Tijdens elke epoch, wordt een deel van de dataset door het netwerk gestuurd. Deze subset van de originele training set noemen we een **batch**. Elke batch wordt door het netwerk gestuurd en de bijhorende output van elke input wordt bijgehouden. De correctheid van de outputs wordt vervolgens opgemeten en geaggregeerd. Op basis hiervan worden dan de gewichten en offset van het netwerk aangepast.\n",
        "\n",
        "TODO: Figuur van trainingsproces?\n",
        "\n",
        "De grootte van de batch kan naar voorkeur ook worden aangepast.\n",
        "\n",
        "Onderstaande code gebruikt de waarden `x` en `y` uit onze training set om het model te trainen. Het draait voor 500 _epochs_, met 64 stukjes data in elke _batch_. We geven ook enkele gegevens door voor _validatie_. Zoals je zult zien als je code uitvoert is dit een vrij intensief proces. Het trainen van een AI model vraagt heel wat rekenkracht, en dit is een super simpel model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8hQKr4cVOdE",
        "outputId": "e275e119-9fea-451e-89ae-6b3746cbf96d"
      },
      "outputs": [],
      "source": [
        "# Train the model on our training data while validating on our validation set\n",
        "history_1 = model_1.fit(x_train, y_train, epochs=500, batch_size=64,\n",
        "                        validation_data=(x_validate, y_validate))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cRE8KpEqVfaS"
      },
      "source": [
        "### 3. Analyse van de statistieken\n",
        "\n",
        "In dit deel gaan we dieper in op de prestaties van ons getrained model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SDsjqfjFm7Fz"
      },
      "source": [
        "**1. Loss (of gemiddelde kwadratische fout)**\n",
        "<!-- Loss (or Mean Squared Error) -->\n",
        "\n",
        "Tijdens het trainen, wordt de prestatie van het model constant gemeten op basis van de trainings data en de validatie data (aparte data set). Het trainingsproces voorziet een volledige historiek van de prestaties van het model tijdens het trainen zodat we de evolutie van het trainingsproces achteraf kunnen analyseren.\n",
        "\n",
        "In volgende secties gaan we hier dieper op in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CmvA-ksoln8r",
        "outputId": "220ea767-6ffd-4eab-c327-c82a016c10eb"
      },
      "outputs": [],
      "source": [
        "# Draw a graph of the loss, which is the distance between\n",
        "# the predicted and actual values during training and validation.\n",
        "train_loss = history_1.history['loss']\n",
        "val_loss = history_1.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "plt.plot(epochs, train_loss, 'g.', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iOFBSbPcYCN4"
      },
      "source": [
        "De grafiek toont de **loss** (verlies). Dit is het verschil tussen de door het model voorspelde waarde en de eigenlijk data en dit voor elke epoch. De `loss`-waarde wordt hierbij per epoch bepaald door de gemiddelde kwadratische fout te berekenen (er zijn ook nog andere manieren).\n",
        "\n",
        "Merk op dat er een `loss` wordt getoond voor zowel de originele training set als voor de validatie set.\n",
        "\n",
        "We zien in de grafiek dat de `loss` snel afneemt over de eerste 25 epochs, waarna deze begint te stabiliseren. Dit betekent dat het model in de eerste 25 epochs sterk verbetert en nauwkeurigere voorspellingen produceert.\n",
        "\n",
        "Ons doel is om te stoppen met trainen wanneer het niet meer verbeterd of wanneer de `training loss` lager wordt dan de `validation loss`, in welk geval het model geleerd heeft om de trainings data zo goed te voorspellen dat het niet meer beter kan met nieuwe data.\n",
        "\n",
        "Om te kijken waar we best stoppen met trainen, kunnen we best even inzoomen op de grafiek op het gedeelte **na de eerste 50 epochs**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Zo0RYroFZYIV",
        "outputId": "8dc7544d-9504-4ec8-e362-d8dab905a474"
      },
      "outputs": [],
      "source": [
        "# Exclude the first few epochs so the graph is easier to read\n",
        "SKIP = 50\n",
        "\n",
        "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W4EQD-Bb8hLM"
      },
      "source": [
        "Uit de grafiek kunnen we concluderen dat de `loss` daalt tot ongeveer 200 epochs. Vanaf daar begint het te stabiliseren. Dit betekent dat we eigenlijk **na 200 epochs kunnen stoppen** met het trainen van ons model.\n",
        "\n",
        "We kunnen echter ook zien dat de laagste `loss` rond de `0.155` ligt. Dit betekent dat de voorspellingen van ons netwerk gemiddeld `~15%` afwijken. Bovendien springen de `validation loss` waarden veel rond en zijn ze soms zelfs hoger.\n",
        "\n",
        "TODO: We kunnen echter ook zien dat de laagste `loss` rond de `0.145` ligt. Dit betekent dat de voorspellingen van ons netwerk gemiddeld `~14%` afwijken. Daarnaast zien we dat de `validation loss` waarden een stuk hoger liggen, namelijk rond de `0.165`.\n",
        "\n",
        "**2. Gemiddelde absolute fout**\n",
        "<!-- Mean Absolute Error -->\n",
        "\n",
        "Om meer inzicht te krijgen in de prestaties van ons model kunnen we wat meer gegevens in een grafiek plaatsen. Deze keer zullen we de gemiddelde absolute fout analyseren, wat een andere manier is om te meten hoe ver de voorspellingen van het netwerk verwijderd zijn van de werkelijke waarden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Md9E_azmpkZU",
        "outputId": "e47fe879-5e16-4e3c-9e98-279059955384"
      },
      "outputs": [],
      "source": [
        "plt.clf()\n",
        "\n",
        "# Draw a graph of mean absolute error, which is another way of\n",
        "# measuring the amount of error in the prediction.\n",
        "train_mae = history_1.history['mae']\n",
        "val_mae = history_1.history['val_mae']\n",
        "\n",
        "plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ctawd0CXAVEw"
      },
      "source": [
        "Deze grafiek van _gemiddelde absolute fout_ vertelt een ander verhaal. We kunnen zien dat trainings gegevens consistent minder fouten vertonen dan validatie gegevens, wat betekent dat het netwerk mogelijks **overfit** is, of de trainingsgegevens zo goed heeft geleerd dat het geen effectieve voorspellingen kan doen over nieuwe gegevens.\n",
        "\n",
        "Bovendien zijn de `MAE` waarden behoorlijk hoog, op zijn best `~0,305`, wat betekent dat sommige voorspellingen van het model er minstens `30%` naast zitten. Een fout van `30%` betekent dat we nog ver verwijderd zijn van het nauwkeurig modelleren van de sinusgolf functie.\n",
        "\n",
        "#### Overfitting\n",
        "\n",
        "Overfitting in een neuraal netwerk verwijst naar een situatie waarin het model de trainingsgegevens te goed heeft geleerd en te complex is geworden, zodat het begint te passen bij de ruis in de gegevens in plaats van bij het onderliggende patroon. Dit resulteert in slechte generalisatieprestaties, wat betekent dat het model goed presteert op de trainingsgegevens, maar slecht op nieuwe, ongeziene gegevens.\n",
        "\n",
        "<!--\n",
        "MSE vs MAE\n",
        "In summary, MSE and MAE are both measures of the difference between the predictions and actual values, with MSE emphasizing larger errors and MAE providing a more robust measurement. The choice of loss function depends on the nature of the problem and the desired trade-off between sensitivity to larger errors and robustness to outliers.\n",
        "-->\n",
        "\n",
        "#### 3. Echte waarden versus voorspelde waarden\n",
        "\n",
        "Laten we, om meer inzicht te krijgen in wat er gebeurt, de voorspellingen vergelijken met de testdataset die we eerder opzij hebben gezet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "i13eVIT3B9Mj",
        "outputId": "6004cf7f-77d3-4cb9-fa0d-49bdc591301e"
      },
      "outputs": [],
      "source": [
        "# Calculate and print the loss on our test dataset\n",
        "test_loss, test_mae = model_1.evaluate(x_test, y_test)\n",
        "\n",
        "# Make predictions based on our test dataset\n",
        "y_test_pred = model_1.predict(x_test)\n",
        "\n",
        "# Graph the predictions against the actual values\n",
        "plt.clf()\n",
        "plt.title('Comparison of predictions and actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual values')\n",
        "plt.plot(x_test, y_test_pred, 'r.', label='TF predictions')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wokallj1D21L"
      },
      "source": [
        "Slecht nieuws. De grafiek maakt duidelijk dat ons netwerk geleerd heeft om de sinusfunctie zeer beperkt te benaderen.\n",
        "\n",
        "De rigiditeit van deze fit suggereert dat het model niet genoeg capaciteit heeft om de volledige complexiteit van de sinusgolf functie te leren. Door ons model groter te maken, zouden we de prestaties ervan moeten kunnen verbeteren.\n",
        "\n",
        "Merk op dat dit net het omgekeerde is van een overfit, waar het model te complex is. Nu aangezien we maar 1 hidden layer hebben, is de kans wel heel klein dat we met een overfit zitten."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T7sL-hWtoAZC"
      },
      "source": [
        "## Trainen van een groter model\n",
        "\n",
        "Open de 2de notebook `larger_model.ipynb` om verder te gaan."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "train_hello_world_model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ts-flow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "c0ea710cafb71a266f03a737cf23e3fdf9c852cca513aca12152c31d3d9485ff"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
