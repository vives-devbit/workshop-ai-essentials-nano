{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZBFzjClURz"
      },
      "source": [
        "# Trainen van een simpel TensorFlow Lite model voor microcontrollers\n",
        "\n",
        "Deze notebook demonstreert het proces voor het trainen van een `2.5 kB` model met TensorFlow en het converteren voor gebruik met TensorFlow Lite voor microcontrollers.\n",
        "\n",
        "Deep learning netwerken leren patronen in onderliggende data te modelleren. Hier gaan we een netwerk trainen om gegevens te modelleren die zijn gegenereerd door een sinus functie. Dit zal resulteren in een model dat een waarde, `x`, kan aannemen en zijn sinus, `y`, kan voorspellen.\n",
        "\n",
        "Deze notebook is gebaseerd op de originele [hello world demo van TensorFlow Lite](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In een virtuele environment\n",
        "\n",
        "Je kan deze notebook ook runnen op een computer in een virtuele python environment aan de hand van `conda`.\n",
        "\n",
        "```bash\n",
        "conda create -n ts-flow python=3.9\n",
        "conda activate ts-flow\n",
        "```\n",
        "\n",
        "Vergeet in VSCode dan niet om je kernel correct te zetten."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UQblnrLd_ET"
      },
      "source": [
        "## Configure Defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PYwRFppd-WB"
      },
      "outputs": [],
      "source": [
        "# Define paths to model files\n",
        "import os\n",
        "MODELS_DIR = 'models/'\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + 'model'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dh4AXGuHWeu1"
      },
      "source": [
        "## Opzetten van omgeving\n",
        "\n",
        "Installeren van de nodige libraries. Hier in commentaar gezet omdat dit reeds voor jullie is gedaan. Dit duurt ook vrij lang.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr1VLfotanf6",
        "outputId": "510567d6-300e-40e2-f5b8-c3520a3f3a8b"
      },
      "outputs": [],
      "source": [
        "# ! pip install tensorflow==2.4.0\n",
        "# ! pip install pandas\n",
        "# ! pip install matplotlib"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tx9lOPWh9grN"
      },
      "source": [
        "Importeren van de nodige libraries.\n",
        "- **tensorflow:** open source machine learning library\n",
        "- **keras:** high-level API rond tensorflow voor deep learning\n",
        "- **numpy:** wiskundige library\n",
        "- **panda:** data manipulatie library\n",
        "- **matplotlib:** library voor grafieken\n",
        "- **math:** wiskundige library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53PBJBv1jEtJ"
      },
      "outputs": [],
      "source": [
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "\n",
        "# Keras is TensorFlow's high-level API for deep learning\n",
        "from tensorflow import keras\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "# Pandas is a data manipulation library \n",
        "import pandas as pd\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# Math is Python's math library\n",
        "import math\n",
        "\n",
        "# Set seed for experiment reproducibility\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p-PuBEb6CMeo"
      },
      "source": [
        "## Maken van een simpele dataset\n",
        "\n",
        "In deze stap gaan we een artificiële dataset generen. In de realiteit zouden we dit bv. kunnen opmeten met een automatische meetopstelling.\n",
        "\n",
        "In de praktijk is het model maar zo goed als de originele dataset waarmee we het trainen. Vandaar dat het in de praktijk heel belangrijk is om een goede dataset te hebben."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7gB0-dlNmLT-"
      },
      "source": [
        "### 1. Genereren van de data\n",
        "\n",
        "In onderstaande code genereren we een random set van `x` waarden. Voor elke `x` waarde berekenen we dan de `sinus(x)`, welke dan onze `y` waarden worden.\n",
        "\n",
        "Het resultaat geven we terug in een grafiek."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uKjg7QeMDsDx",
        "outputId": "2ded7790-62a2-40df-a4f9-429f2dd5357f"
      },
      "outputs": [],
      "source": [
        "# Number of sample datapoints\n",
        "SAMPLES = 1000\n",
        "\n",
        "# Generate a uniformly distributed set of random numbers in the range from\n",
        "# 0 to 2π, which covers a complete sine wave oscillation\n",
        "x_values = np.random.uniform(\n",
        "    low=0, high=2*math.pi, size=SAMPLES).astype(np.float32)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "# Calculate the corresponding sine values\n",
        "y_values = np.sin(x_values).astype(np.float32)\n",
        "\n",
        "# Plot our data. The 'b.' argument tells the library to print blue dots.\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iWOlC7W_FYvA"
      },
      "source": [
        "### 2. Toevoegen van ruis\n",
        "\n",
        "Onze data werd rechtstreeks gegeneerd door de sinus functie en heeft daarom een mooie vorm.\n",
        "\n",
        "Machine learning modellen zijn echter goed in het extraheren van de onderliggende betekenis van rommelige data uit de echte wereld. Om dit aan te tonen, kunnen we wat ruis aan onze data toevoegen om een iets realistischere situatie te benaderen.\n",
        "\n",
        "Onderstaande code voegt wat willekeurige ruis toe aan elke waarde. Het resultaat wordt opnieuw in een grafiek weergegeven."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "i0FJe3Y-Gkac",
        "outputId": "10d4d994-3b78-4512-a029-5ef0e444d75c"
      },
      "outputs": [],
      "source": [
        "# Add a small random number to each y value\n",
        "y_values += 0.1 * np.random.randn(*y_values.shape)\n",
        "\n",
        "# Plot our data\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Up8Xk_pMH4Rt"
      },
      "source": [
        "### 3. Splits de data\n",
        "\n",
        "De dataset die we nu hebben gemaakt is een benadering van een realistische dataset. Deze waarden gaan we nu gebruiken om ons model te trainen.\n",
        "\n",
        "Om de nauwkeurigheid van het model dat we trainen te evalueren, moeten we de voorspellingen vergelijken met echte gegevens en controleren hoe goed ze overeenkomen. Deze evaluatie vindt plaats tijdens de training (waar dit **validatie** wordt genoemd) en na de training (ook wel **testen** genoemd). In beide gevallen is het belangrijk dat we nieuwe gegevens gebruiken die nog niet zijn gebruikt om het model te trainen.\n",
        "\n",
        "We dienen onze dataset dus op te splitsen in 3 groepen:\n",
        "\n",
        "1. **Trainingsdata:** 60% (het grootste aantal gebruiken we om het model te trainen)\n",
        "2. **Validatie:** 20% (wordt gebruikt tijdens het trainen om model bij te sturen)\n",
        "3. **Testen:** 20% (wordt gebruikt na het trainen om te kijken hoe goed het model werkt)\n",
        "\n",
        "Onderstaande code zal onze originele dataset opsplitsen in deze verschillende sets en grafisch weergeven met elk hun eigen kleur."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "nNYko5L1keqZ",
        "outputId": "e1e6915d-5cfe-4086-d20f-8e3aebd80292"
      },
      "outputs": [],
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Training\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Testing\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wfdelu1TmgPk"
      },
      "source": [
        "## Training\n",
        "\n",
        "Nu onze dataset klaar is, kunnen we starten met het maken van een neuraal netwerk om het vervolgens te trainen met de data die we uit vorige stap hebben."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t5McVnHmNiDw"
      },
      "source": [
        "### 1. Creëren van een Model\n",
        "\n",
        "In deze stap gaan we een simpel neural netwerk model bouwen dat een input waarde (hier in ons geval de `x` parameter) neemt en dit gebruikt om de bijhorende sinus waarde te voorspellen (hier voorgesteld door `y`).\n",
        "\n",
        "In dit geval hebben we te maken met **regressie**. Regressie is een statistische methode die in AI wordt gebruikt om de relatie tussen een afhankelijke variabele en een of meer onafhankelijke variabelen te modelleren. Het wordt gebruikt voor het voorspellen van continue waarden (reële getallen) voor een bepaalde invoer. Het model wordt vervolgens gebruikt om voorspellingen te doen op nieuwe, ongeziene gegevens.\n",
        "\n",
        "TODO: Is onderstaande correct?\n",
        "\n",
        "Het neuraal netwerk zal bestaan uit volgende onderdelen:\n",
        "\n",
        "1. Een input die onze `x` waarde zal bevatten\n",
        "2. Een **hidden layer** met 8 **neuronen**\n",
        "    - Op basis van deze input zal elk neuron _geactiveerd_ worden met een bepaalde waarde en dit op basis van zijn interne parameters (_gewicht_ (_weight_) en _offset_ (_bias_)). De activeringsgraad van een neuron wordt uitgedrukt als een getal.\n",
        "3. Een **output** layer die het resultaat van de 8 neuronen zal samennemen om een voorspelling te maken van de `y` waarde\n",
        "    - De activeringsnummers van onze verborgen layer zullen als invoer worden gebruikt voor onze output layer, die een enkele neuron is. Het zal zijn eigen gewichten en offset toepassen op deze invoer en zijn eigen activering berekenen, die zal resulteren in een `y`-waarde.\n",
        "\n",
        "<!-- De input is hier niet echt een layer maar eerder een input object. Meer info hier: [https://www.tensorflow.org/guide/keras/sequential_model](https://www.tensorflow.org/guide/keras/sequential_model). -->\n",
        "\n",
        "![Neural Network](./img/neural_network.jpg)\n",
        "\n",
        "TODO: Update drawing above\n",
        "\n",
        "De code hieronder maakt een model zoals we hierboven hebben beschreven. Eens dit samengesteld is compileren we dit zodat het klaar is om te trainen.\n",
        "\n",
        "Als output zie je een klein overzicht van je gemaakt model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gD60bE8cXQId"
      },
      "outputs": [],
      "source": [
        "# We'll use Keras to create a simple model architecture\n",
        "model_1 = tf.keras.Sequential(name=\"basic-model\")\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 8 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model_1.add(keras.layers.Dense(8, activation='relu', input_shape=(1,), name=\"hidden-layer\"))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model_1.add(keras.layers.Dense(1, name=\"output-layer\"))\n",
        "\n",
        "# Compile the model using the standard 'adam' optimizer and the mean squared error or 'mse' loss function for regression.\n",
        "model_1.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Output some information about the model\n",
        "model_1.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "O0idLyRLQeGj"
      },
      "source": [
        "### 2. Trainen van het Model\n",
        "\n",
        "Zodra we het model hebben gedefinieerd, kunnen we onze gegevens gebruiken om het te **trainen**. Training bestaat uit aanvoeren van een `x`-waarde aan het neurale netwerk, controleren hoe ver de output van het netwerk afwijkt van de verwachte `y`-waarde en het aanpassen van de gewichten en offsets van de neuronen, zodat de kans groter is dat de output de volgende keer correct is.\n",
        "\n",
        "Training voert dit proces meerdere keren uit op de volledige dataset en elke volledige doorloop wordt een **epoch** genoemd. Het aantal epochs dat tijdens de training moet worden uitgevoerd, is een parameter die we kunnen instellen.\n",
        "\n",
        "Tijdens elke epoch, wordt een deel van de dataset door het netwerk gestuurd. Deze subset van de originele training set noemen we een **batch**. Elke batch wordt door het netwerk gestuurd en de bijhorende output van elke input wordt bijgehouden. De correctheid van de outputs wordt vervolgens opgemeten en geaggregeerd. Op basis hiervan worden dan de gewichten en offset van het netwerk aangepast.\n",
        "\n",
        "TODO: Figuur van trainingsproces?\n",
        "\n",
        "De grootte van de batch kan naar voorkeur ook worden aangepast.\n",
        "\n",
        "Onderstaande code gebruikt de waarden `x` en `y` uit onze training set om het model te trainen. Het draait voor 500 _epochs_, met 64 stukjes data in elke _batch_. We geven ook enkele gegevens door voor _validatie_. Zoals je zult zien als je code uitvoert is dit een vrij intensief proces. Het trainen van een AI model vraagt heel wat rekenkracht, en dit is een super simpel model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8hQKr4cVOdE",
        "outputId": "e275e119-9fea-451e-89ae-6b3746cbf96d"
      },
      "outputs": [],
      "source": [
        "# Train the model on our training data while validating on our validation set\n",
        "history_1 = model_1.fit(x_train, y_train, epochs=500, batch_size=64,\n",
        "                        validation_data=(x_validate, y_validate))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cRE8KpEqVfaS"
      },
      "source": [
        "### 3. Analyse van de statistieken\n",
        "\n",
        "In dit deel gaan we dieper in op de prestaties van ons getrained model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SDsjqfjFm7Fz"
      },
      "source": [
        "**1. Loss (of gemiddelde kwadratische fout)**\n",
        "<!-- Loss (or Mean Squared Error) -->\n",
        "\n",
        "Tijdens het trainen, wordt de prestatie van het model constant gemeten op basis van de trainings data en de validatie data (aparte data set). Het trainingsproces voorziet een volledige historiek van de prestaties van het model tijdens het trainen zodat we de evolutie van het trainingsproces achteraf kunnen analyseren.\n",
        "\n",
        "In volgende secties gaan we hier dieper op in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "CmvA-ksoln8r",
        "outputId": "220ea767-6ffd-4eab-c327-c82a016c10eb"
      },
      "outputs": [],
      "source": [
        "# Draw a graph of the loss, which is the distance between\n",
        "# the predicted and actual values during training and validation.\n",
        "train_loss = history_1.history['loss']\n",
        "val_loss = history_1.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "plt.plot(epochs, train_loss, 'g.', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "iOFBSbPcYCN4"
      },
      "source": [
        "De grafiek toont de **loss** (verlies). Dit is het verschil tussen de door het model voorspelde waarde en de eigenlijk data en dit voor elke epoch. De `loss`-waarde wordt hierbij per epoch bepaald door de gemiddelde kwadratische fout te berekenen (er zijn ook nog andere manieren).\n",
        "\n",
        "Merk op dat er een `loss` wordt getoond voor zowel de originele training set als voor de validatie set.\n",
        "\n",
        "We zien in de grafiek dat de `loss` snel afneemt over de eerste 25 epochs, waarna deze begint te stabiliseren. Dit betekent dat het model in de eerste 25 epochs sterk verbetert en nauwkeurigere voorspellingen produceert.\n",
        "\n",
        "Ons doel is om te stoppen met trainen wanneer het niet meer verbeterd of wanneer de `training loss` lager wordt dan de `validation loss`, in welk geval het model geleerd heeft om de trainings data zo goed te voorspellen dat het niet meer beter kan met nieuwe data.\n",
        "\n",
        "Om te kijken waar we best stoppen met trainen, kunnen we best even inzoomen op de grafiek op het gedeelte **na de eerste 50 epochs**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Zo0RYroFZYIV",
        "outputId": "8dc7544d-9504-4ec8-e362-d8dab905a474"
      },
      "outputs": [],
      "source": [
        "# Exclude the first few epochs so the graph is easier to read\n",
        "SKIP = 50\n",
        "\n",
        "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "W4EQD-Bb8hLM"
      },
      "source": [
        "Uit de grafiek kunnen we concluderen dat de `loss` daalt tot ongeveer 200 epochs. Vanaf daar begint het te stabiliseren. Dit betekent dat we eigenlijk **na 200 epochs kunnen stoppen** met het trainen van ons model.\n",
        "\n",
        "We kunnen echter ook zien dat de laagste `loss` rond de `0.155` ligt. Dit betekent dat de voorspellingen van ons netwerk gemiddeld `~15%` afwijken. Bovendien springen de `validation loss` waarden veel rond en zijn ze soms zelfs hoger.\n",
        "\n",
        "TODO: We kunnen echter ook zien dat de laagste `loss` rond de `0.145` ligt. Dit betekent dat de voorspellingen van ons netwerk gemiddeld `~14%` afwijken. Daarnaast zien we dat de `validation loss` waarden een stuk hoger liggen, namelijk rond de `0.165`.\n",
        "\n",
        "**2. Gemiddelde absolute fout**\n",
        "<!-- Mean Absolute Error -->\n",
        "\n",
        "Om meer inzicht te krijgen in de prestaties van ons model kunnen we wat meer gegevens in een grafiek plaatsen. Deze keer zullen we de gemiddelde absolute fout analyseren, wat een andere manier is om te meten hoe ver de voorspellingen van het netwerk verwijderd zijn van de werkelijke waarden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "Md9E_azmpkZU",
        "outputId": "e47fe879-5e16-4e3c-9e98-279059955384"
      },
      "outputs": [],
      "source": [
        "plt.clf()\n",
        "\n",
        "# Draw a graph of mean absolute error, which is another way of\n",
        "# measuring the amount of error in the prediction.\n",
        "train_mae = history_1.history['mae']\n",
        "val_mae = history_1.history['val_mae']\n",
        "\n",
        "plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ctawd0CXAVEw"
      },
      "source": [
        "Deze grafiek van _gemiddelde absolute fout_ vertelt een ander verhaal. We kunnen zien dat trainings gegevens consistent minder fouten vertonen dan validatie gegevens, wat betekent dat het netwerk mogelijks **overfit** is, of de trainingsgegevens zo goed heeft geleerd dat het geen effectieve voorspellingen kan doen over nieuwe gegevens.\n",
        "\n",
        "Bovendien zijn de `MAE` waarden behoorlijk hoog, op zijn best `~0,305`, wat betekent dat sommige voorspellingen van het model er minstens `30%` naast zitten. Een fout van `30%` betekent dat we nog ver verwijderd zijn van het nauwkeurig modelleren van de sinusgolf functie.\n",
        "\n",
        "#### Overfitting\n",
        "\n",
        "Overfitting in een neuraal netwerk verwijst naar een situatie waarin het model de trainingsgegevens te goed heeft geleerd en te complex is geworden, zodat het begint te passen bij de ruis in de gegevens in plaats van bij het onderliggende patroon. Dit resulteert in slechte generalisatieprestaties, wat betekent dat het model goed presteert op de trainingsgegevens, maar slecht op nieuwe, ongeziene gegevens.\n",
        "\n",
        "<!--\n",
        "MSE vs MAE\n",
        "In summary, MSE and MAE are both measures of the difference between the predictions and actual values, with MSE emphasizing larger errors and MAE providing a more robust measurement. The choice of loss function depends on the nature of the problem and the desired trade-off between sensitivity to larger errors and robustness to outliers.\n",
        "-->\n",
        "\n",
        "#### 3. Echte waarden versus voorspelde waarden\n",
        "\n",
        "Laten we, om meer inzicht te krijgen in wat er gebeurt, de voorspellingen vergelijken met de testdataset die we eerder opzij hebben gezet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "i13eVIT3B9Mj",
        "outputId": "6004cf7f-77d3-4cb9-fa0d-49bdc591301e"
      },
      "outputs": [],
      "source": [
        "# Calculate and print the loss on our test dataset\n",
        "test_loss, test_mae = model_1.evaluate(x_test, y_test)\n",
        "\n",
        "# Make predictions based on our test dataset\n",
        "y_test_pred = model_1.predict(x_test)\n",
        "\n",
        "# Graph the predictions against the actual values\n",
        "plt.clf()\n",
        "plt.title('Comparison of predictions and actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual values')\n",
        "plt.plot(x_test, y_test_pred, 'r.', label='TF predictions')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Wokallj1D21L"
      },
      "source": [
        "Slecht nieuws. De grafiek maakt duidelijk dat ons netwerk geleerd heeft om de sinusfunctie zeer beperkt te benaderen.\n",
        "\n",
        "De rigiditeit van deze fit suggereert dat het model niet genoeg capaciteit heeft om de volledige complexiteit van de sinusgolf functie te leren. Door ons model groter te maken, zouden we de prestaties ervan moeten kunnen verbeteren.\n",
        "\n",
        "Merk op dat dit net het omgekeerde is van een overfit, waar het model te complex is. Nu aangezien we maar 1 hidden layer hebben, is de kans wel heel klein dat we met een overfit zitten."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T7sL-hWtoAZC"
      },
      "source": [
        "## Trainen van een groter model\n",
        "\n",
        "Door extra layers en neuronen toe te voegen kan je een model groter maken en krijgt het dus meer capaciteit om te leren."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aQd0JSdOoAbw"
      },
      "source": [
        "### 1. Maken van een groter model\n",
        "\n",
        "Om ons model groter te maken gaan we een extra layer toevoegen na de originele hidden layer. Ook gaan we beide layers uit 16 neuronen laten bestaan in plaats van 8.\n",
        "\n",
        "TODO: Figuur van netwerk\n",
        "\n",
        "Merk wel op dat dit er zal voor zorgen dat het trainingsproces meer tijd in beslag zal nemen en dat ons uiteindelijk model ook meer geheugen zal nodig hebben."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW0xus6AF-4o"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential(name=\"larger-model\")\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model.add(keras.layers.Dense(16, activation='relu', input_shape=(1,), name=\"hidden-layer-0\"))\n",
        "\n",
        "# The new second and third layer will help the network learn more complex representations\n",
        "model.add(keras.layers.Dense(16, activation='relu', name=\"hidden-layer-1\"))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model.add(keras.layers.Dense(1, name=\"output-layer\"))\n",
        "\n",
        "# Compile the model using the standard 'adam' optimizer and the mean squared error or 'mse' loss function for regression.\n",
        "model.compile(optimizer='adam', loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Output some information about the model\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv2SC409Grap"
      },
      "source": [
        "### 2. Trainen van het groter model\n",
        "\n",
        "Laat ons vervolgens ook opnieuw dit model trainen.\n",
        "\n",
        "**Opgelet! Als je onderstaande code om de een of andere reden nog eens zou uitvoeren, dan dien je bovenstaande code ook eerst opnieuw uit te voeren!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPAUrdkmGq1M",
        "outputId": "b0b50b8b-f5fc-4433-db0e-703697443b76"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=500, batch_size=64,\n",
        "                    validation_data=(x_validate, y_validate))\n",
        "\n",
        "# Save the model to disk\n",
        "model.save(MODEL_TF)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc_CQu2_IvOP"
      },
      "source": [
        "### 3. Grafiek van de statistieken\n",
        "\n",
        "Elke training epoch drukt het model het verlies en de gemiddelde absolute fout af voor training en validatie. U kunt dit lezen in de uitvoer hierboven (merk op dat uw exacte cijfers kunnen verschillen):\n",
        "\n",
        "```\n",
        "Epoch 500/500\n",
        "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0870 - val_loss: 0.0111 - val_mae: 0.0848\n",
        "```\n",
        "\n",
        "Je kan zien dat we al een enorme verbetering hebben\n",
        "\n",
        "- de `validation loss` is gedaald van `0,15` naar `0,01`\n",
        "- de `validatie MAE` is gedaald van `0,33` naar `0,08`\n",
        "\n",
        "De volgende cel zal dezelfde grafieken afdrukken die we gebruikten om ons oorspronkelijke model te evalueren, maar met onze nieuwe trainingsgeschiedenis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "SYHGswAJJgrC",
        "outputId": "0b4baed5-9565-45c7-9fcc-2fd59a86d438"
      },
      "outputs": [],
      "source": [
        "# Draw a graph of the loss, which is the distance between\n",
        "# the predicted and actual values during training and validation.\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Exclude the first few epochs so the graph is easier to read\n",
        "SKIP = 200\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "\n",
        "# Draw a graph of mean absolute error, which is another way of\n",
        "# measuring the amount of error in the prediction.\n",
        "train_mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f86dWOyZKmN9"
      },
      "source": [
        "Dit zijn mooie resultaten. Uit deze grafieken kunnen we verschillende positieve dingen zien:\n",
        "\n",
        "* De algemene `loss` en `MAE` zijn veel beter dan ons vorige netwerk\n",
        "* Metrics zijn beter voor validatie dan voor training, wat betekent dat het netwerk niet overfitt is\n",
        "\n",
        "De reden dat de statistieken voor validatie beter zijn dan die voor training, is dat validatiestatistieken worden berekend aan het einde van elke *epoch*, terwijl trainingsstatistieken gedurende de hele trainingsperiode worden berekend, dus validatie vindt plaats op een model dat iets langer is getraind.\n",
        "\n",
        "Dit alles betekent dat ons netwerk goed lijkt te presteren. Laten we ter bevestiging de voorspellingen vergelijken met de test dataset die we eerder opzij hebben gezet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "lZfztKKyhLxX",
        "outputId": "f48f33ad-aba0-4c62-ba15-cc742bd23805"
      },
      "outputs": [],
      "source": [
        "# Calculate and print the loss on our test dataset\n",
        "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Make predictions based on our test dataset\n",
        "y_test_pred = model.predict(x_test)\n",
        "\n",
        "# Graph the predictions against the actual values\n",
        "plt.clf()\n",
        "plt.title('Comparison of predictions and actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual values')\n",
        "plt.plot(x_test, y_test_pred, 'r.', label='TF predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3h7IcvuOOS4J"
      },
      "source": [
        "Veel beter. De voorspellingen komen visueel vrij goed overeen met onze gegevens.\n",
        "\n",
        "Het model is niet perfect. De voorspellingen vormen geen vloeiende sinuscurve. De lijn is bijvoorbeeld bijna recht als `x` tussen `2,5` en `4,5` ligt. Als we verder zouden willen gaan, zouden we kunnen proberen de capaciteit van het model verder te vergroten, misschien door enkele technieken te gebruiken om overfitting te voorkomen.\n",
        "\n",
        "Een belangrijk onderdeel van machine learning is echter **weten wanneer te stoppen**. Dit model is goed genoeg voor onze use case - namelijk om sommige LED's in een aangenaam patroon te laten knipperen.\n",
        "\n",
        "## Genereren van een TensorFlow Lite model\n",
        "\n",
        "Onze volgende stappen bestaan eruit om een model te genereren dat we op de microcontroller kunnen runnen. Hiervoor moeten we ons TensorFlow model omvormen naar een TensorFlow Lite model. Natuurlijk moeten we het dan ook nog omzetten in code."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sHe-Wv47rhm8"
      },
      "source": [
        "### 1. Genereren van een Model met en zonder kwantisatie\n",
        "\n",
        "We hebben nu een acceptabel nauwkeurig model. We gebruiken de [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert) om het model om te zetten in een speciaal, ruimtebesparend formaat voor gebruik op devices met beperkte geheugencapaciteit.\n",
        "\n",
        "Aangezien dit model op een microcontroller wordt ingezet, willen we dat het zo klein mogelijk is. Een techniek om de grootte van een model te verkleinen, wordt **[kwantisatie](https://www.tensorflow.org/lite/performance/post_training_quantization)** (quantization) genoemd. Het vermindert de precisie van de gewichten van het model, en mogelijk ook de activeringen (uitvoer van elke laag), wat geheugen bespaart, vaak zonder veel invloed op de nauwkeurigheid te hebben. Gekwantiseerde modellen werken ook sneller, omdat de vereiste berekeningen eenvoudiger zijn (gehele getallen versus komma getallen).\n",
        "\n",
        "In de volgende sectie gaan we het model twee keer converteren: één keer met kwantisatie, één keer zonder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1muAoUm8lSXL",
        "outputId": "aad8259e-df57-4f03-da77-d490e5609d9f"
      },
      "outputs": [],
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
        "model_no_quant_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
        "\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "def representative_dataset():\n",
        "  for i in range(500):\n",
        "    yield([x_train[i].reshape(1, 1)])\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Enforce integer only quantization\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "# Provide a representative dataset to ensure we quantize correctly.\n",
        "converter.representative_dataset = representative_dataset\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vE-ZDkHVxe"
      },
      "source": [
        "### 2. Vergelijking van de performantie van beide modellen\n",
        "\n",
        "Om te bewijzen dat deze modellen nauwkeurig zijn, zelfs na conversie en kwantisatie, zullen we hun voorspellingen en verlies vergelijken met onze testdataset.\n",
        "\n",
        "<!-- We define the `predict` (for predictions) and `evaluate` (for loss) functions for TFLite models. *Note: These are already included in a TF model, but not in  a TFLite model.* -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "NKtmxEhko1S1"
      },
      "outputs": [],
      "source": [
        "def predict_tflite(tflite_model, x_test):\n",
        "  # Prepare the test data\n",
        "  x_test_ = x_test.copy()\n",
        "  x_test_ = x_test_.reshape((x_test.size, 1))\n",
        "  x_test_ = x_test_.astype(np.float32)\n",
        "\n",
        "  # Initialize the TFLite interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model,\n",
        "                                    experimental_op_resolver_type=tf.lite.experimental.OpResolverType.BUILTIN_REF)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  # If required, quantize the input layer (from float to integer)\n",
        "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "  if (input_scale, input_zero_point) != (0.0, 0):\n",
        "    x_test_ = x_test_ / input_scale + input_zero_point\n",
        "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
        "  \n",
        "  # Invoke the interpreter\n",
        "  y_pred = np.empty(x_test_.size, dtype=output_details[\"dtype\"])\n",
        "  for i in range(len(x_test_)):\n",
        "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
        "    interpreter.invoke()\n",
        "    y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "  \n",
        "  # If required, dequantized the output layer (from integer to float)\n",
        "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "  if (output_scale, output_zero_point) != (0.0, 0):\n",
        "    y_pred = y_pred.astype(np.float32)\n",
        "    y_pred = (y_pred - output_zero_point) * output_scale\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "def evaluate_tflite(tflite_model, x_test, y_true):\n",
        "  global model\n",
        "  y_pred = predict_tflite(tflite_model, x_test)\n",
        "  loss_function = tf.keras.losses.get(model.loss)\n",
        "  loss = loss_function(y_true, y_pred).numpy()\n",
        "  return loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pLZLY0D4gl6U"
      },
      "source": [
        "**1. Voorspellingen**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RS3zni1gkrt"
      },
      "outputs": [],
      "source": [
        "# Calculate predictions\n",
        "y_test_pred_tf = model.predict(x_test)\n",
        "y_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, x_test)\n",
        "y_test_pred_tflite = predict_tflite(model_tflite, x_test)\n",
        "\n",
        "# Compare predictions\n",
        "plt.clf()\n",
        "plt.title('Comparison of various models against actual values')\n",
        "plt.plot(x_test, y_test, 'bo', label='Actual values')\n",
        "plt.plot(x_test, y_test_pred_tf, 'ro', label='TF predictions')\n",
        "plt.plot(x_test, y_test_pred_no_quant_tflite, 'bx', label='TFLite predictions')\n",
        "plt.plot(x_test, y_test_pred_tflite, 'gx', label='TFLite quantized predictions')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V7vlfJqbiZMU"
      },
      "source": [
        "**2. Loss (MSE - Gemiddelde kwadratische fout)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpHifyGZRhw8"
      },
      "outputs": [],
      "source": [
        "# Calculate loss\n",
        "loss_tf, _ = model.evaluate(x_test, y_test, verbose=0)\n",
        "loss_no_quant_tflite = evaluate_tflite(model_no_quant_tflite, x_test, y_test)\n",
        "loss_tflite = evaluate_tflite(model_tflite, x_test, y_test)\n",
        "\n",
        "# Compare loss\n",
        "df = pd.DataFrame.from_records(\n",
        "    [[\"TensorFlow\", loss_tf],\n",
        "     [\"TensorFlow Lite\", loss_no_quant_tflite],\n",
        "     [\"TensorFlow Lite Quantized\", loss_tflite]],\n",
        "     columns = [\"Model\", \"Loss/MSE\"], index=\"Model\").round(4)\n",
        "df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E7Vjw7VckLu1"
      },
      "source": [
        "**3. Grootte in geheugen**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEXiJ8dFkL2R"
      },
      "outputs": [],
      "source": [
        "# Calculate size\n",
        "size_tf = os.path.getsize(MODEL_TF)\n",
        "size_no_quant_tflite = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
        "size_tflite = os.path.getsize(MODEL_TFLITE)\n",
        "\n",
        "# Compare size\n",
        "pd.DataFrame.from_records(\n",
        "    [[\"TensorFlow\", f\"{size_tf} bytes\", \"\"],\n",
        "     [\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \", f\"(reduced by {size_tf - size_no_quant_tflite} bytes)\"],\n",
        "     [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\", f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
        "     columns = [\"Model\", \"Size\", \"\"], index=\"Model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXdmfo7imGMB"
      },
      "source": [
        "**Summary**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R1LVMA2nkM_l"
      },
      "source": [
        "We kunnen aan de hand van de voorspellingen (grafiek) en de `loss` (tabel) zien dat het originele TF-model, het TFLite-model en het gekwantiseerde TFLite-model allemaal dicht genoeg bij elkaar liggen - ook al verschillen ze in grootte (tabel). Dit impliceert dat het gekwantiseerde (kleinste) model klaar is voor gebruik.\n",
        "\n",
        "*Opmerking: het gekwantiseerde (integer) TFLite-model is slechts 500 bytes kleiner dan het originele (float) TFLite-model - een kleine verkleining! Dit komt doordat het model al zo klein is dat kwantisering minder effect heeft. Complexe modellen met meer gewicht kunnen tot 4x kleiner worden!*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HPSFmDL7pv2L"
      },
      "source": [
        "## Genereren van een TensorFlow Lite model voor microcontrollers\n",
        "\n",
        "Hier converteren we het gekwantiseerde model van TensorFlow Lite naar een C-bronbestand dat kan worden geladen door TensorFlow Lite voor microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1FB4ieeg0lw",
        "outputId": "c25b75c6-a28d-47b1-9b3a-b7ba821ee310"
      },
      "outputs": [],
      "source": [
        "# Install xxd if it is not available\n",
        "# !apt update && apt -qq install xxd\n",
        "\n",
        "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "\n",
        "# Update variable names\n",
        "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}\n",
        "\n",
        "# Print the C source file\n",
        "!cat {MODEL_TFLITE_MICRO}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JvRy0ZyMhQOX"
      },
      "source": [
        "## Implementeren op een microcontroller\n",
        "\n",
        "Je kan nu de instructies volgen in de slides om het model te implementeren in de bijhorende demo applicatie. Zo kan het model worden uitgevoerd op de microcontroller."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "train_hello_world_model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ts-flow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "c0ea710cafb71a266f03a737cf23e3fdf9c852cca513aca12152c31d3d9485ff"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
