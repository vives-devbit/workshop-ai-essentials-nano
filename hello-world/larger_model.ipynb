{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZBFzjClURz"
      },
      "source": [
        "# Trainen van een Groter Model\n",
        "\n",
        "Het vorige model bleek te klein te zijn om de sinus deftig te voorspellen. Daarom trainen we nu een groter model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UQblnrLd_ET"
      },
      "source": [
        "## Configure Defaults"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PYwRFppd-WB"
      },
      "outputs": [],
      "source": [
        "# Define paths to model files\n",
        "import os\n",
        "MODELS_DIR = 'models/'\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + 'model'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53PBJBv1jEtJ"
      },
      "outputs": [],
      "source": [
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "\n",
        "# Keras is TensorFlow's high-level API for deep learning\n",
        "from tensorflow import keras\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "# Pandas is a data manipulation library \n",
        "import pandas as pd\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# Math is Python's math library\n",
        "import math\n",
        "\n",
        "# Set seed for experiment reproducibility\n",
        "seed = 1\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "p-PuBEb6CMeo"
      },
      "source": [
        "## Maken van een simpele dataset\n",
        "\n",
        "We maken opnieuw een dataset met ruis en splitsen deze dan op in 3 delen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uKjg7QeMDsDx",
        "outputId": "2ded7790-62a2-40df-a4f9-429f2dd5357f"
      },
      "outputs": [],
      "source": [
        "# Number of sample datapoints\n",
        "SAMPLES = 1000\n",
        "\n",
        "# Generate a uniformly distributed set of random numbers in the range from\n",
        "# 0 to 2Ï€, which covers a complete sine wave oscillation\n",
        "x_values = np.random.uniform(\n",
        "    low=0, high=2*math.pi, size=SAMPLES).astype(np.float32)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "np.random.shuffle(x_values)\n",
        "\n",
        "# Calculate the corresponding sine values\n",
        "y_values = np.sin(x_values).astype(np.float32)\n",
        "\n",
        "# Add a small random number to each y value\n",
        "y_values += 0.1 * np.random.randn(*y_values.shape)\n",
        "\n",
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Training\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Testing\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validation\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T7sL-hWtoAZC"
      },
      "source": [
        "## Trainen van een groter model\n",
        "\n",
        "Door extra layers en neuronen toe te voegen kan je een model groter maken en krijgt het dus meer capaciteit om te leren."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aQd0JSdOoAbw"
      },
      "source": [
        "### 1. Maken van een groter model\n",
        "\n",
        "Om ons model groter te maken gaan we een extra layer toevoegen na de originele hidden layer. Ook gaan we beide layers uit 16 neuronen laten bestaan in plaats van 8.\n",
        "\n",
        "TODO: Figuur van netwerk\n",
        "\n",
        "Merk wel op dat dit er zal voor zorgen dat het trainingsproces meer tijd in beslag zal nemen en dat ons uiteindelijk model ook meer geheugen zal nodig hebben."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oW0xus6AF-4o"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential(name=\"larger-model\")\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "model.add(keras.layers.Dense(16, activation='relu', input_shape=(1,), name=\"hidden-layer-0\"))\n",
        "\n",
        "# The new second and third layer will help the network learn more complex representations\n",
        "model.add(keras.layers.Dense(16, activation='relu', name=\"hidden-layer-1\"))\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model.add(keras.layers.Dense(1, name=\"output-layer\"))\n",
        "\n",
        "# Compile the model using the standard 'adam' optimizer and the mean squared error or 'mse' loss function for regression.\n",
        "model.compile(optimizer='adam', loss=\"mse\", metrics=[\"mae\"])\n",
        "\n",
        "# Output some information about the model\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv2SC409Grap"
      },
      "source": [
        "### 2. Trainen van het groter model\n",
        "\n",
        "Laat ons vervolgens ook opnieuw dit model trainen.\n",
        "\n",
        "**Opgelet! Als je onderstaande code om de een of andere reden nog eens zou uitvoeren, dan dien je bovenstaande code ook eerst opnieuw uit te voeren!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPAUrdkmGq1M",
        "outputId": "b0b50b8b-f5fc-4433-db0e-703697443b76"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=500, batch_size=64,\n",
        "                    validation_data=(x_validate, y_validate))\n",
        "\n",
        "# Save the model to disk\n",
        "model.save(MODEL_TF)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc_CQu2_IvOP"
      },
      "source": [
        "### 3. Grafiek van de statistieken\n",
        "\n",
        "Elke training epoch drukt het model het verlies en de gemiddelde absolute fout af voor training en validatie. U kunt dit lezen in de uitvoer hierboven (merk op dat uw exacte cijfers kunnen verschillen):\n",
        "\n",
        "```\n",
        "Epoch 500/500\n",
        "10/10 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0870 - val_loss: 0.0111 - val_mae: 0.0848\n",
        "```\n",
        "\n",
        "Je kan zien dat we al een enorme verbetering hebben\n",
        "\n",
        "- de `validation loss` is gedaald van `0,15` naar `0,01`\n",
        "- de `validatie MAE` is gedaald van `0,33` naar `0,08`\n",
        "\n",
        "De volgende cel zal dezelfde grafieken afdrukken die we gebruikten om ons oorspronkelijke model te evalueren, maar met onze nieuwe trainingsgeschiedenis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "SYHGswAJJgrC",
        "outputId": "0b4baed5-9565-45c7-9fcc-2fd59a86d438"
      },
      "outputs": [],
      "source": [
        "# Draw a graph of the loss, which is the distance between\n",
        "# the predicted and actual values during training and validation.\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(train_loss) + 1)\n",
        "\n",
        "# Exclude the first few epochs so the graph is easier to read\n",
        "SKIP = 200\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "\n",
        "# Draw a graph of mean absolute error, which is another way of\n",
        "# measuring the amount of error in the prediction.\n",
        "train_mae = history.history['mae']\n",
        "val_mae = history.history['val_mae']\n",
        "\n",
        "plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "f86dWOyZKmN9"
      },
      "source": [
        "Dit zijn mooie resultaten. Uit deze grafieken kunnen we verschillende positieve dingen zien:\n",
        "\n",
        "* De algemene `loss` en `MAE` zijn veel beter dan ons vorige netwerk\n",
        "* Metrics zijn beter voor validatie dan voor training, wat betekent dat het netwerk niet overfitt is\n",
        "\n",
        "De reden dat de statistieken voor validatie beter zijn dan die voor training, is dat validatiestatistieken worden berekend aan het einde van elke *epoch*, terwijl trainingsstatistieken gedurende de hele trainingsperiode worden berekend, dus validatie vindt plaats op een model dat iets langer is getraind.\n",
        "\n",
        "Dit alles betekent dat ons netwerk goed lijkt te presteren. Laten we ter bevestiging de voorspellingen vergelijken met de test dataset die we eerder opzij hebben gezet:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "lZfztKKyhLxX",
        "outputId": "f48f33ad-aba0-4c62-ba15-cc742bd23805"
      },
      "outputs": [],
      "source": [
        "# Calculate and print the loss on our test dataset\n",
        "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
        "\n",
        "# Make predictions based on our test dataset\n",
        "y_test_pred = model.predict(x_test)\n",
        "\n",
        "# Graph the predictions against the actual values\n",
        "plt.clf()\n",
        "plt.title('Comparison of predictions and actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual values')\n",
        "plt.plot(x_test, y_test_pred, 'r.', label='TF predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "3h7IcvuOOS4J"
      },
      "source": [
        "Veel beter. De voorspellingen komen visueel vrij goed overeen met onze gegevens.\n",
        "\n",
        "Het model is niet perfect. De voorspellingen vormen geen vloeiende sinuscurve. De lijn is bijvoorbeeld bijna recht als `x` tussen `2,5` en `4,5` ligt. Als we verder zouden willen gaan, zouden we kunnen proberen de capaciteit van het model verder te vergroten, misschien door enkele technieken te gebruiken om overfitting te voorkomen.\n",
        "\n",
        "Een belangrijk onderdeel van machine learning is echter **weten wanneer te stoppen**. Dit model is goed genoeg voor onze use case - namelijk om sommige LED's in een aangenaam patroon te laten knipperen.\n",
        "\n",
        "## Genereren van een TensorFlow Lite model\n",
        "\n",
        "Onze volgende stappen bestaan eruit om een model te genereren dat we op de microcontroller kunnen runnen. Hiervoor moeten we ons TensorFlow model omvormen naar een TensorFlow Lite model. Natuurlijk moeten we het dan ook nog omzetten in code."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sHe-Wv47rhm8"
      },
      "source": [
        "### 1. Genereren van een Model met en zonder kwantisatie\n",
        "\n",
        "We hebben nu een acceptabel nauwkeurig model. We gebruiken de [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert) om het model om te zetten in een speciaal, ruimtebesparend formaat voor gebruik op devices met beperkte geheugencapaciteit.\n",
        "\n",
        "Aangezien dit model op een microcontroller wordt ingezet, willen we dat het zo klein mogelijk is. Een techniek om de grootte van een model te verkleinen, wordt **[kwantisatie](https://www.tensorflow.org/lite/performance/post_training_quantization)** (quantization) genoemd. Het vermindert de precisie van de gewichten van het model, en mogelijk ook de activeringen (uitvoer van elke laag), wat geheugen bespaart, vaak zonder veel invloed op de nauwkeurigheid te hebben. Gekwantiseerde modellen werken ook sneller, omdat de vereiste berekeningen eenvoudiger zijn (gehele getallen versus komma getallen).\n",
        "\n",
        "In de volgende sectie gaan we het model twee keer converteren: Ã©Ã©n keer met kwantisatie, Ã©Ã©n keer zonder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1muAoUm8lSXL",
        "outputId": "aad8259e-df57-4f03-da77-d490e5609d9f"
      },
      "outputs": [],
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
        "model_no_quant_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
        "\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "def representative_dataset():\n",
        "  for i in range(500):\n",
        "    yield([x_train[i].reshape(1, 1)])\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Enforce integer only quantization\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "# Provide a representative dataset to ensure we quantize correctly.\n",
        "converter.representative_dataset = representative_dataset\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vE-ZDkHVxe"
      },
      "source": [
        "### 2. Vergelijking van de performantie van beide modellen\n",
        "\n",
        "Om te bewijzen dat deze modellen nauwkeurig zijn, zelfs na conversie en kwantisatie, zullen we hun voorspellingen en verlies vergelijken met onze testdataset.\n",
        "\n",
        "<!-- We define the `predict` (for predictions) and `evaluate` (for loss) functions for TFLite models. *Note: These are already included in a TF model, but not in  a TFLite model.* -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "NKtmxEhko1S1"
      },
      "outputs": [],
      "source": [
        "def predict_tflite(tflite_model, x_test):\n",
        "  # Prepare the test data\n",
        "  x_test_ = x_test.copy()\n",
        "  x_test_ = x_test_.reshape((x_test.size, 1))\n",
        "  x_test_ = x_test_.astype(np.float32)\n",
        "\n",
        "  # Initialize the TFLite interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model,\n",
        "                                    experimental_op_resolver_type=tf.lite.experimental.OpResolverType.BUILTIN_REF)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  # If required, quantize the input layer (from float to integer)\n",
        "  input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "  if (input_scale, input_zero_point) != (0.0, 0):\n",
        "    x_test_ = x_test_ / input_scale + input_zero_point\n",
        "    x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
        "  \n",
        "  # Invoke the interpreter\n",
        "  y_pred = np.empty(x_test_.size, dtype=output_details[\"dtype\"])\n",
        "  for i in range(len(x_test_)):\n",
        "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
        "    interpreter.invoke()\n",
        "    y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "  \n",
        "  # If required, dequantized the output layer (from integer to float)\n",
        "  output_scale, output_zero_point = output_details[\"quantization\"]\n",
        "  if (output_scale, output_zero_point) != (0.0, 0):\n",
        "    y_pred = y_pred.astype(np.float32)\n",
        "    y_pred = (y_pred - output_zero_point) * output_scale\n",
        "\n",
        "  return y_pred\n",
        "\n",
        "def evaluate_tflite(tflite_model, x_test, y_true):\n",
        "  global model\n",
        "  y_pred = predict_tflite(tflite_model, x_test)\n",
        "  loss_function = tf.keras.losses.get(model.loss)\n",
        "  loss = loss_function(y_true, y_pred).numpy()\n",
        "  return loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pLZLY0D4gl6U"
      },
      "source": [
        "**1. Voorspellingen**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RS3zni1gkrt"
      },
      "outputs": [],
      "source": [
        "# Calculate predictions\n",
        "y_test_pred_tf = model.predict(x_test)\n",
        "y_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, x_test)\n",
        "y_test_pred_tflite = predict_tflite(model_tflite, x_test)\n",
        "\n",
        "# Compare predictions\n",
        "plt.clf()\n",
        "plt.title('Comparison of various models against actual values')\n",
        "plt.plot(x_test, y_test, 'bo', label='Actual values')\n",
        "plt.plot(x_test, y_test_pred_tf, 'ro', label='TF predictions')\n",
        "plt.plot(x_test, y_test_pred_no_quant_tflite, 'bx', label='TFLite predictions')\n",
        "plt.plot(x_test, y_test_pred_tflite, 'gx', label='TFLite quantized predictions')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "V7vlfJqbiZMU"
      },
      "source": [
        "**2. Loss (MSE - Gemiddelde kwadratische fout)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpHifyGZRhw8"
      },
      "outputs": [],
      "source": [
        "# Calculate loss\n",
        "loss_tf, _ = model.evaluate(x_test, y_test, verbose=0)\n",
        "loss_no_quant_tflite = evaluate_tflite(model_no_quant_tflite, x_test, y_test)\n",
        "loss_tflite = evaluate_tflite(model_tflite, x_test, y_test)\n",
        "\n",
        "# Compare loss\n",
        "df = pd.DataFrame.from_records(\n",
        "    [[\"TensorFlow\", loss_tf],\n",
        "     [\"TensorFlow Lite\", loss_no_quant_tflite],\n",
        "     [\"TensorFlow Lite Quantized\", loss_tflite]],\n",
        "     columns = [\"Model\", \"Loss/MSE\"], index=\"Model\").round(4)\n",
        "df"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "E7Vjw7VckLu1"
      },
      "source": [
        "**3. Grootte in geheugen**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEXiJ8dFkL2R"
      },
      "outputs": [],
      "source": [
        "# Calculate size\n",
        "size_tf = os.path.getsize(MODEL_TF)\n",
        "size_no_quant_tflite = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
        "size_tflite = os.path.getsize(MODEL_TFLITE)\n",
        "\n",
        "# Compare size\n",
        "pd.DataFrame.from_records(\n",
        "    [[\"TensorFlow\", f\"{size_tf} bytes\", \"\"],\n",
        "     [\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \", f\"(reduced by {size_tf - size_no_quant_tflite} bytes)\"],\n",
        "     [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\", f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
        "     columns = [\"Model\", \"Size\", \"\"], index=\"Model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXdmfo7imGMB"
      },
      "source": [
        "**Summary**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "R1LVMA2nkM_l"
      },
      "source": [
        "We kunnen aan de hand van de voorspellingen (grafiek) en de `loss` (tabel) zien dat het originele TF-model, het TFLite-model en het gekwantiseerde TFLite-model allemaal dicht genoeg bij elkaar liggen - ook al verschillen ze in grootte (tabel). Dit impliceert dat het gekwantiseerde (kleinste) model klaar is voor gebruik.\n",
        "\n",
        "*Opmerking: het gekwantiseerde (integer) TFLite-model is slechts 500 bytes kleiner dan het originele (float) TFLite-model - een kleine verkleining! Dit komt doordat het model al zo klein is dat kwantisering minder effect heeft. Complexe modellen met meer gewicht kunnen tot 4x kleiner worden!*"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "HPSFmDL7pv2L"
      },
      "source": [
        "## Genereren van een TensorFlow Lite model voor microcontrollers\n",
        "\n",
        "Hier converteren we het gekwantiseerde model van TensorFlow Lite naar een C-bronbestand dat kan worden geladen door TensorFlow Lite voor microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1FB4ieeg0lw",
        "outputId": "c25b75c6-a28d-47b1-9b3a-b7ba821ee310"
      },
      "outputs": [],
      "source": [
        "# Install xxd if it is not available\n",
        "# !apt update && apt -qq install xxd\n",
        "\n",
        "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "\n",
        "# Update variable names\n",
        "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}\n",
        "\n",
        "# Print the C source file\n",
        "!cat {MODEL_TFLITE_MICRO}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JvRy0ZyMhQOX"
      },
      "source": [
        "## Implementeren op een microcontroller\n",
        "\n",
        "Je kan nu de instructies volgen in de slides om het model te implementeren in de bijhorende demo applicatie. Zo kan het model worden uitgevoerd op de microcontroller."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "train_hello_world_model.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ts-flow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "c0ea710cafb71a266f03a737cf23e3fdf9c852cca513aca12152c31d3d9485ff"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
